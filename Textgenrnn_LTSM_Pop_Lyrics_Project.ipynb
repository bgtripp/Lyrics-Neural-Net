{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Textgenrnn LTSM Pop Lyrics Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bgtripp/Lyrics-Neural-Net/blob/master/Textgenrnn_LTSM_Pop_Lyrics_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVaUXv7Gqg-8",
        "colab_type": "code",
        "outputId": "976b085b-d811-4f45-9f3b-5ae3a79b9ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "#Copyright Ben Tripp 2020\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "#Helpful site: https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/walkerkq/musiclyrics/master/billboard_lyrics_1964-2015.csv'\n",
        "\n",
        "song_data = pd.read_csv(url, encoding = \"latin-1\") #Pandas dataframe\n",
        "song_data.head() #Shows the first 5 lines of the dataframe"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>wooly bully</td>\n",
              "      <td>sam the sham and the pharaohs</td>\n",
              "      <td>1965</td>\n",
              "      <td>sam the sham miscellaneous wooly bully wooly b...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>i cant help myself sugar pie honey bunch</td>\n",
              "      <td>four tops</td>\n",
              "      <td>1965</td>\n",
              "      <td>sugar pie honey bunch you know that i love yo...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>i cant get no satisfaction</td>\n",
              "      <td>the rolling stones</td>\n",
              "      <td>1965</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>you were on my mind</td>\n",
              "      <td>we five</td>\n",
              "      <td>1965</td>\n",
              "      <td>when i woke up this morning you were on my mi...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>youve lost that lovin feelin</td>\n",
              "      <td>the righteous brothers</td>\n",
              "      <td>1965</td>\n",
              "      <td>you never close your eyes anymore when i kiss...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rank  ... Source\n",
              "0     1  ...    3.0\n",
              "1     2  ...    1.0\n",
              "2     3  ...    1.0\n",
              "3     4  ...    1.0\n",
              "4     5  ...    1.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr-NTyJfIclv",
        "colab_type": "code",
        "outputId": "9af22eb3-529d-4e00-c1c1-db0f18d379b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "year = 1995\n",
        "\n",
        "subset = song_data[song_data['Year'] == year]\n",
        "lyrics = subset['Lyrics']\n",
        "lyrics.to_csv(r'lyrics.txt', header=None, index=None, sep=' ', mode='a')\n",
        "file_name = 'lyrics.txt'\n",
        "model_name = '{}PopLyrics'.format(year)\n",
        "\n",
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer default 20\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}\n",
        "\n",
        "lyrics.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000     as i walk through the valley of the shadow of...\n",
              "3001     a lonely mother gazing out of her window star...\n",
              "3002     creep oh ah oh ah oh ah yeah creep oh ah oh a...\n",
              "3003     there used to be a greying tower alone on the...\n",
              "3004     darlin i cant explain where did we lose our w...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHS65jOuTZGl",
        "colab_type": "code",
        "outputId": "40638c33-f8d7-48c1-c580-a81afbfba815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "99 texts collected.\n",
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 134,051 character sequences.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "130/130 [==============================] - 300s 2s/step - loss: 2.9125\n",
            "Epoch 2/20\n",
            "130/130 [==============================] - 295s 2s/step - loss: 2.8314\n",
            "Epoch 3/20\n",
            "130/130 [==============================] - 298s 2s/step - loss: 2.6709\n",
            "Epoch 4/20\n",
            "130/130 [==============================] - 299s 2s/step - loss: 2.2370\n",
            "Epoch 5/20\n",
            "130/130 [==============================] - 295s 2s/step - loss: 2.0979\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" i want you wang the whang mand whe want the want the in the whe the and the want me the wang the want the whe the want the want the want the want you want the baby and i want you want to the want the whe the want the want to you want and i want i want and she the want the want the want the want \n",
            "\n",
            "\" of the whe and the whe whe want the want the sont i want the the the want a love the want the whe want the and the goow you goow the whong the want you want the want the son the want though you want you wint thong and the want i want the the want the want and the the whe want the want the the in\n",
            "\n",
            "\" i wint and the want whe want the want the what you want the whe song the want the want the wang the want the whe want the sont the want thing the wang the dont the want to the in the thang the wind the want i want the want the want the whe wint the want the song and the want the the in the want \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" up i whahe ind you of the be it the and the whe me tho mand and the sant bet the bus i want fean burt hond the me i mome in she stan the want the goow to im tore and bay the dont to i hes i gan to you in to makn and i song the want you wint to so live anow and he is thet sont you dont thonght me\n",
            "\n",
            "\" bay your a dong a want in the rint and love ind to the want bere thah and and the and ofr on youre wre kne high then thong whou you ond it whe ind tous sight that you want i tent i way you fore thing so thingh and i backane i got whe the ane and bur bat tho goon bush mike i dont do and and fof a\n",
            "\n",
            "\" thingh you dand and you cond whang that his my you nont i cane you dind you cace bast the foow you youn you babe and mand the ind a want baby migte so the wang cand fore med in my hee heas and he ond you whant to you goom tous the it andinga the hond it tous i cane what i wank i wanon that in th\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" athyoust Ì¢cre therny in ame mit pack and menkent burane onne morut ifazepes th thures ir shar nande hat ind thapel beracntwan frophes i wame weth lontso ah chay my to a love yournoxdnd wnysilind banwene wath yerougin a ol it nant how wost abcas ond live ginddloury acke sees now i cincin \"\n",
            "\n",
            "\" none sow ane the romeer soy baby hacly ir my mond be mige ig a kndang gohh henaringt by paby all lly one srannt whe pino bon cas mont ory i candery not you gtous ley tiu ands the rios norcse thi becyy ne pall buromt illy yout best lay tost feer thig gon the sed you muknebe goe out woh be mes dow\n",
            "\n",
            "\" whok yerr babay at aan uh so mand terteny i whe tot yourechesztp anwee bupps live thong hove uphh berbyilmy thy cangte wantinw all furd your i finilsl indy idn dere it this you rithe a mcm wale whal whou dove evee you toust at the wint i berame toe gour evel ikna frqousn an sres bovest all that \n",
            "\n",
            "Epoch 6/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 1.9141\n",
            "Epoch 7/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 1.7582\n",
            "Epoch 8/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 1.6071\n",
            "Epoch 9/20\n",
            "130/130 [==============================] - 299s 2s/step - loss: 1.4701\n",
            "Epoch 10/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 1.3760\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" i wanna be baby that youre on my mind i wanna see you want me to me my mind you want me to me i can say i let you go and i will love you the good to me our love i wanna be baby that your body down to the ground the way i dont wanna be all i wanna be all i ask of your body down to the ground and \n",
            "\n",
            "\" i wanna be baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby \n",
            "\n",
            "\" i wanna be but you want me to me our me mine i wanna be baby that your bet a girl with you i wanna be baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby baby think i wanna be with you the good from the back to me i think about you a wish i wanna be bab\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" the back to me our me mine the waitter i will me i wanna look i never tonk the sprong and all i think a for and i wanna be by touch you i think i see youre goon for me could cause i got a get of your broken my like you mounh you say i dont want to be my manay there i dont wanna be alone to love \n",
            "\n",
            "\" uh the way i want to be when the more come from the love in the rarey on the line of the baby want to be my mind you i wanna be baby baby baby baby baby that your body down to fearin work the wit i get a feeling and the way i love you but your got i gied love with you the raby that you deep the \n",
            "\n",
            "\" the becouss i will be around around the way i day a beaning beant to can some giver me she me i can say that i want to be baby down to the good for meary me come on the sun comes and in the way i get on me my mind you go and my mind the backin in man the fill come and i think about you the time \n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" of the way i spoe thise its outter i deep to around mure mean buzt parted really whink my masy you one my mind my swap lave i wanna heay fan is baby day hont to me ouz ap seemersees up in an payeph its backt take musching you uh the fack a feriot mack me mores so i get of your eyspects uniliors \n",
            "\n",
            "\" that i car do im baby butterberthin he canties junt to merardy youre im fetting the livelerer crey im feel to make mure to daying to gotta me fromething you wanta supharoday that it reeps you weak ow my my in my mind the bead the time i need a how the sudge drielime whill ever done i whink ya sw\n",
            "\n",
            "\" i know oh ouh hhill it porsis and all i couse dree me out you to know hemeres when yeah as oh mur i visat your love my spanted timeby baby sprop that my moncoss not doont speam tojued now then i neel to be goon girl want to be think i keep asound for no the wear puzz to know shit whonks farsst m\n",
            "\n",
            "Epoch 11/20\n",
            "130/130 [==============================] - 296s 2s/step - loss: 1.2861\n",
            "Epoch 12/20\n",
            "130/130 [==============================] - 299s 2s/step - loss: 1.2097\n",
            "Epoch 13/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 1.1432\n",
            "Epoch 14/20\n",
            "130/130 [==============================] - 298s 2s/step - loss: 1.0800\n",
            "Epoch 15/20\n",
            "130/130 [==============================] - 299s 2s/step - loss: 1.0241\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\" i want to talk to you i want you to tell her that i guess you are not alone alone alone alone alone you all the time of day i dont want no short dick man dont want to know you let me be the way i do and i want to say it i will wake up happy i will do all the time of day on the day i get of you t\n",
            "\n",
            "\" i want to talk to you i dont even want to say it down on sunday every day of the week oh oh oh oh oh oh oh oh oh oh oh oh oh oh ah oh ah oh ah oh ah oh ah oh ah oh ah oh ah yeah yeah im whoop come on you want me to and i will so let her walk the good the back to me i gotta got a hat peep the way\n",
            "\n",
            "\" i want you to then tell me how you see what you do me right there and i thank you thank you wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk wenk\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\" i wanna love you thank you that i got the pain that man with a love so when you turn it up turn it up turn it upside dont want no short dick man dick man nothing its all right but and whoop whoop whoop whoop whoop come on the good to you i gotta got the eny you do it had he sang but all right an\n",
            "\n",
            "\" i want to love so timing to my life my love some fun up huh heart to show it so engung tell me whoop whoop comin on out on the house of stone and light i dont know whats alone the wind can silled if you nother dit i got to your down down down down down disnt know that your pody do you were right\n",
            "\n",
            "\" i wanna chill on dung it because in the time hes mines place i let you go where did you go where did you go where did you go where did you go where did you come from where did you come from where did you go where did you go where did you go where did you want me to and ill conderstary this is ho\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "\" it sout it over trits shit slow he stop saysod tootsie roll come on and give me and a true alone theres not at eveny day hit off my fatter here eppulla besd ar all o40 chohch no a rex with because hey be when i will sotsil you slop me eyes epalisest only eveer tells you are a wern goes the with \n",
            "\n",
            "\" that all your love of stone and light i will a kieded around my handwell me and theres of your wryimm this yeah uh mun huh is prets oh babybry but topal lift make light im back good washi tooking foll on my monoest just come i got for you iss go its a smome jco little thing the pain suifis becon\n",
            "\n",
            "\" cause i was toll find here jussecred another urtil to shes lefl me but dew to go mantiomertallle there sight its all fun about another nigge in the mornin rain donnive right and right baby baby baby show you dayd hurtoult gamped spriontwell me been knowwher side wayim tome fun up spot get you wh\n",
            "\n",
            "Epoch 16/20\n",
            "130/130 [==============================] - 300s 2s/step - loss: 0.9721\n",
            "Epoch 17/20\n",
            "130/130 [==============================] - 297s 2s/step - loss: 0.9273\n",
            "Epoch 18/20\n",
            "130/130 [==============================] - 296s 2s/step - loss: 0.8874\n",
            "Epoch 19/20\n",
            " 96/130 [=====================>........] - ETA: 1:17 - loss: 0.8530"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_4ejAmU0vXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io4SrgQ2Tibk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen = textgenrnn(weights_path='{}_weights.hdf5'.format(model_name),\n",
        "                      vocab_path='{}_vocab.json'.format(model_name),\n",
        "                      config_path='{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE7i01aqUO91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen.generate_samples()\n",
        "#yl.n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}